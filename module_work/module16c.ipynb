{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"module16c.ipynb","provenance":[],"authorship_tag":"ABX9TyOcoV5PnXIPNqjEmYLgF52O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s4gZqfAvwrFE","executionInfo":{"status":"ok","timestamp":1658077137822,"user_tz":420,"elapsed":26396,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}},"outputId":"0c8953c6-8c32-4c33-cda7-1274269ea598"},"outputs":[{"output_type":"stream","name":"stdout","text":["Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:13 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [85.6 kB]\n","Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,526 kB]\n","Get:15 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,057 kB]\n","Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,897 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,329 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,302 kB]\n","Fetched 11.5 MB in 6s (2,053 kB/s)\n","Reading package lists... Done\n"]}],"source":["import os\n","# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.3'\n","spark_version = 'spark-3.0.3'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"]},{"cell_type":"code","source":["# start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName('Tokens').getOrCreate()"],"metadata":{"id":"pp2iEdrawt8C","executionInfo":{"status":"ok","timestamp":1658077147610,"user_tz":420,"elapsed":9797,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# create a function to return the length of a list\n","def word_list_length(word_list):\n","  return len(word_list)"],"metadata":{"id":"WJRtcIXLxIrz","executionInfo":{"status":"ok","timestamp":1658077149368,"user_tz":420,"elapsed":7,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer"],"metadata":{"id":"roQXTu1rw2_6","executionInfo":{"status":"ok","timestamp":1658077147847,"user_tz":420,"elapsed":244,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["dataframe = spark.createDataFrame([\n","  (0, 'Spark is great'),\n","  (1, 'we are learning spark'),\n","  (2, 'spark is better than Hadoop no doubt')\n","], ['id', 'sentence'])\n","dataframe.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jJuy5yctHNej","executionInfo":{"status":"ok","timestamp":1658077455888,"user_tz":420,"elapsed":233,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}},"outputId":"3bcfa55b-0707-4d6b-b8c1-bbac715c6cf9"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|      Spark is great|\n","|  1|we are learning s...|\n","|  2|spark is better t...|\n","+---+--------------------+\n","\n"]}]},{"cell_type":"code","source":["from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType"],"metadata":{"id":"-zTZpbYzxVJV","executionInfo":{"status":"ok","timestamp":1658077149701,"user_tz":420,"elapsed":340,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# create a user-defined function\n","count_tokens = udf(word_list_length, IntegerType())"],"metadata":{"id":"rXXMki_MxbXS","executionInfo":{"status":"ok","timestamp":1658077205298,"user_tz":420,"elapsed":154,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# create our Tokenizer\n","tokenizer = Tokenizer(inputCol='sentence', outputCol='words')\n","\n","# transform the DataFrame\n","tokenized_df = tokenizer.transform(dataframe)\n","\n","# select the needed columns, don't truncate results\n","tokenized_df.withColumn('tokens', count_tokens(col('words'))).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Un27CmqQGlE5","executionInfo":{"status":"ok","timestamp":1658077460451,"user_tz":420,"elapsed":1385,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}},"outputId":"5fd823af-46d9-4ef5-e00f-b6db98523cb0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+------+\n","|id |sentence                            |words                                       |tokens|\n","+---+------------------------------------+--------------------------------------------+------+\n","|0  |Spark is great                      |[spark, is, great]                          |3     |\n","|1  |we are learning spark               |[we, are, learning, spark]                  |4     |\n","|2  |spark is better than Hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|7     |\n","+---+------------------------------------+--------------------------------------------+------+\n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"AJnwGmc3HB6o"},"execution_count":null,"outputs":[]}]}
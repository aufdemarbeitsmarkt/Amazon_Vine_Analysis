{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"poHAnPg7ZPom","executionInfo":{"status":"ok","timestamp":1657076536598,"user_tz":420,"elapsed":23400,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}},"outputId":"395b4d25-d9cb-4b2f-d28d-941ffc30579c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","\n","--2022-07-06 03:02:01--  http://www.apache.org/dist/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz\n","Resolving www.apache.org (www.apache.org)... 151.101.2.132, 2a04:4e42::644\n","Connecting to www.apache.org (www.apache.org)|151.101.2.132|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://www.apache.org/dist/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz [following]\n","--2022-07-06 03:02:01--  https://www.apache.org/dist/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz\n","Connecting to www.apache.org (www.apache.org)|151.101.2.132|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://downloads.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz [following]\n","--2022-07-06 03:02:01--  https://downloads.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz\n","Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.95.219, 2a01:4f8:10a:201a::2, ...\n","Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 220400553 (210M) [application/x-gzip]\n","Saving to: ‘spark-3.0.3-bin-hadoop2.7.tgz.1’\n","\n","spark-3.0.3-bin-had 100%[===================>] 210.19M  25.5MB/s    in 9.0s    \n","\n","2022-07-06 03:02:10 (23.4 MB/s) - ‘spark-3.0.3-bin-hadoop2.7.tgz.1’ saved [220400553/220400553]\n","\n"]}],"source":["import os\n","# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.2'\n","spark_version = 'spark-3.0.3'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"XxTH7C7oSHhh","executionInfo":{"status":"ok","timestamp":1657076546035,"user_tz":420,"elapsed":9446,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}}},"outputs":[],"source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Demographics\").getOrCreate()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HT_VAZmzZGqe","executionInfo":{"status":"ok","timestamp":1657076555380,"user_tz":420,"elapsed":9353,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}},"outputId":"e82d89f5-34d2-4459-c6d2-5aaa3a2514cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---+-----------------+---+--------+---------+--------+--------------------+---------------+------+--------------------+\n","| id|             name|age|height_m|weight_kg|children|          occupation|academic_degree|salary|            location|\n","+---+-----------------+---+--------+---------+--------+--------------------+---------------+------+--------------------+\n","|  1|    Glad Gavrieli| 38|    1.52|       74|       0|Computer Systems ...|       Bachelor|    78|           Louisiana|\n","|  2|  Henrieta Fittes| 34|    1.72|       39|       4|             Teacher|         Master|    44|            Illinois|\n","|  3|   Peyton Dulanty| 24|     1.8|       47|       5|Senior Quality En...|            PhD|    44|      North Carolina|\n","|  4|     Denna Morgen| 48|    1.81|       71|       5|   Account Executive|         Master|    81|          California|\n","|  5|    Camella Izaks| 34|    1.65|       60|       1|   Director of Sales|            PhD|    76|                Ohio|\n","|  6|     Shara Esposi| 49|     1.5|       52|       2|     Sales Associate|         Master|    68|            Virginia|\n","|  7|Saunderson Gudgen| 64|    1.93|       47|       0|Sales Representative|         Master|    85|            New York|\n","|  8|Aldrich Rosendorf| 42|    1.77|       66|       0|        Developer II|            PhD|    84|District of Columbia|\n","|  9| Edlin Washington| 50|    1.74|       52|       4|     Design Engineer|         Master|    88|              Oregon|\n","| 10| Anders Penwright| 55|    1.98|       90|       2|     Project Manager|       Bachelor|   116|             Georgia|\n","| 11|   Ruthie Cubbini| 67|    1.52|       55|       4|     Data Coordiator|            PhD|    51|District of Columbia|\n","| 12|  Juliet Harbidge| 66|    1.61|       49|       2|             Actuary|            PhD|    66|         Mississippi|\n","| 13|  Jeannine Kelner| 30|     1.8|       81|       1|       Programmer II|       Bachelor|    90|              Hawaii|\n","| 14|  Roi Gristhwaite| 66|    1.86|       90|       1|    Product Engineer|       Bachelor|    40|           Tennessee|\n","| 15|      Brant Stark| 58|    1.94|       53|       4|Sales Representative|       Bachelor|    96|      North Carolina|\n","| 16|   Donny Rankling| 26|    1.51|       39|       1|Physical Therapy ...|       Bachelor|   116|            Virginia|\n","| 17|     Dov Gavaghan| 27|    1.58|       68|       5|Computer Systems ...|       Bachelor|    74|                Utah|\n","| 18|    Rosanne Wreak| 37|    1.76|       81|       2|Payment Adjustmen...|         Master|   103|             Florida|\n","| 19|    Belva Spraggs| 50|    1.65|       80|       2|             Teacher|       Bachelor|    46|             Georgia|\n","| 20|      Welch Lease| 21|    1.57|       79|       4|Mechanical System...|         Master|   114|       Massachusetts|\n","+---+-----------------+---+--------+---------+--------+--------------------+---------------+------+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["# Read in data from S3 Buckets\n","from pyspark import SparkFiles\n","# url = \"https://s3.amazonaws.com/dataviz-curriculum/day_1/demographics.csv\" # this file is no longer valid\n","url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.1/22-big-data/day_1/demographics.csv\"\n","spark.sparkContext.addFile(url)\n","df = spark.read.csv(SparkFiles.get(\"demographics.csv\"), sep=\",\", header=True)\n","\n","# Show DataFrame\n","df.show()"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vuhd0Jz_ZTbO","executionInfo":{"status":"ok","timestamp":1657077049528,"user_tz":420,"elapsed":223,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}},"outputId":"e38e44c9-8fea-497c-8bfa-0123962ed46a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['id',\n"," 'name',\n"," 'age',\n"," 'height_m',\n"," 'weight_kg',\n"," 'children',\n"," 'occupation',\n"," 'academic_degree',\n"," 'salary',\n"," 'location']"]},"metadata":{},"execution_count":17}],"source":["# Print the column names\n","df.columns"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dn0OANoaZWjU","executionInfo":{"status":"ok","timestamp":1657076747619,"user_tz":420,"elapsed":467,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}},"outputId":"d1358fe5-720e-4986-890a-df3bc995aea2"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---+-----------------+---+--------+---------+--------+--------------------+---------------+------+--------------------+\n","| id|             name|age|height_m|weight_kg|children|          occupation|academic_degree|salary|            location|\n","+---+-----------------+---+--------+---------+--------+--------------------+---------------+------+--------------------+\n","|  1|    Glad Gavrieli| 38|    1.52|       74|       0|Computer Systems ...|       Bachelor|    78|           Louisiana|\n","|  2|  Henrieta Fittes| 34|    1.72|       39|       4|             Teacher|         Master|    44|            Illinois|\n","|  3|   Peyton Dulanty| 24|     1.8|       47|       5|Senior Quality En...|            PhD|    44|      North Carolina|\n","|  4|     Denna Morgen| 48|    1.81|       71|       5|   Account Executive|         Master|    81|          California|\n","|  5|    Camella Izaks| 34|    1.65|       60|       1|   Director of Sales|            PhD|    76|                Ohio|\n","|  6|     Shara Esposi| 49|     1.5|       52|       2|     Sales Associate|         Master|    68|            Virginia|\n","|  7|Saunderson Gudgen| 64|    1.93|       47|       0|Sales Representative|         Master|    85|            New York|\n","|  8|Aldrich Rosendorf| 42|    1.77|       66|       0|        Developer II|            PhD|    84|District of Columbia|\n","|  9| Edlin Washington| 50|    1.74|       52|       4|     Design Engineer|         Master|    88|              Oregon|\n","| 10| Anders Penwright| 55|    1.98|       90|       2|     Project Manager|       Bachelor|   116|             Georgia|\n","+---+-----------------+---+--------+---------+--------+--------------------+---------------+------+--------------------+\n","only showing top 10 rows\n","\n"]}],"source":["# Print out the first 10 rows\n","df.show(10)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":305},"id":"8QzpRD8dZdsD","executionInfo":{"status":"error","timestamp":1657077097715,"user_tz":420,"elapsed":170,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}},"outputId":"2870fa7c-56b9-4d43-d6d4-ae3540612c4d"},"outputs":[{"output_type":"error","ename":"AnalysisException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-8cb4c81f106f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Select the age, height_meter, and weight_kg columns and use describe to show the summary statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'height_meter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weight_kg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \"\"\"\n\u001b[0;32m-> 1421\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '`height_meter`' given input columns: [academic_degree, age, children, height_m, id, location, name, occupation, salary, weight_kg];;\n'Project [age#18, 'height_meter, weight_kg#20]\n+- Relation[id#16,name#17,age#18,height_m#19,weight_kg#20,children#21,occupation#22,academic_degree#23,salary#24,location#25] csv\n"]}],"source":["# Select the age, height_meter, and weight_kg columns and use describe to show the summary statistics\n","df.select(['age', 'height_meter', 'weight_kg']).describe().show()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ULIuI1pNZfws","executionInfo":{"status":"ok","timestamp":1657077116571,"user_tz":420,"elapsed":9,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}},"outputId":"e2d4715b-d5b7-44e5-9d38-4f88891466a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- id: string (nullable = true)\n"," |-- name: string (nullable = true)\n"," |-- age: string (nullable = true)\n"," |-- height_m: string (nullable = true)\n"," |-- weight_kg: string (nullable = true)\n"," |-- children: string (nullable = true)\n"," |-- occupation: string (nullable = true)\n"," |-- academic_degree: string (nullable = true)\n"," |-- salary: string (nullable = true)\n"," |-- location: string (nullable = true)\n","\n"]}],"source":["# Print the schema to see the types\n","\n","df.printSchema()"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":189},"id":"iuFP8TEZZhfb","executionInfo":{"status":"error","timestamp":1657077270885,"user_tz":420,"elapsed":174,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}},"outputId":"5958bd7b-d893-4a1b-a775-89716fa54378"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-2cd7ff871550>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Rename the Salary column to `Salary (1k)` and show only this new column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Salary (1k)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: withColumnRenamed() missing 1 required positional argument: 'new'"]}],"source":["# Rename the Salary column to `Salary (1k)` and show only this new column\n","df = df.withColumnRenamed('Salary (1k)')"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"NQyUp2OYZjRM","executionInfo":{"status":"ok","timestamp":1657076555385,"user_tz":420,"elapsed":12,"user":{"displayName":"Tim Nilsen","userId":"17919249066029393158"}}},"outputs":[],"source":["# Create a new column called `Salary` where the values are the `Salary (1k)` * 1000\n","# Show the columns `Salary` and `Salary (1k)`\n","df = df.withColumn('Salary', df['Salary (1k)'] * 1000)\n","df.show(10)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"demographics.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false}},"nbformat":4,"nbformat_minor":0}